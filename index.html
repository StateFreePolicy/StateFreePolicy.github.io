<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>
  <title>Do You Need Proprioceptive States in Visuomotor Policies?</title>
  <style>
    body {
      font-family: "Georgia", serif;
      background-color: #f8f7f2;
      color: #111;
      margin: 60px 60px;
      font-size: 20px;
      display: flex;
      justify-content: center;
    }
    .container {
      max-width: 1400px; /* 页面内容最大宽度 */
      width: 100%;
    }
    h1 {
      font-size: 3.5em;  /* 标题再稍微大一些 */
      font-weight: 600;
      line-height: 1.3;
    }
    .meta {
      margin-top: 50px;
      font-size: 1.4em; /* Published 更大 */
    }
    .abstract {
      margin-top: 50px;
      font-size: 1.4em; /* Published 更大 */
      text-align: justify;  /* 两端对齐 */
    }
    .section {
      margin-top: 50px;
      font-size: 1.4em; /* Published 更大 */
      text-align: justify;  /* 两端对齐 */
    }
    .bibtex {
      font-size: 3em;
      margin-top: 50px;
      font-size: 1.8em; /* Published 更大 */
      text-align: justify;  /* 两端对齐 */
    }
    .authors {
      margin-top: 30px;
      margin-bottom: 40px;
      font-size: 1.4em;
      text-align: left;  /* 左对齐 */
      line-height: 1.6;
    }
    .authors sup {
      font-size: 0.9em;
    }
    .authors .notes {
      font-size: 0.9em;
      margin-top: 10px;
      font-style: italic;
    }
    .authors .affiliations {
      font-size: 0.9em;
      margin-top: 10px;
      line-height: 1.4;
    }
    .button {
      display: inline-flex;
      align-items: center;
      gap: 14px;
      margin-top: 50px;
      padding: 10px 34px;
      border: 2px dashed #555;
      font-family: monospace;
      font-size: 1.8em;  /* Paper 按钮字体更大 */
      background: #f8f7f2;
      cursor: pointer;
      text-decoration: none;
      color: #111;
    }
    .button:hover {
      background: #eaeaea;
    }
    .button img {
      height: 1.6em; /* 图标高度随文字缩放 */
      width: auto;
    }

    .video-row {
      display: flex;
      margin-top: 50px;
      gap: 20px;
      overflow-x: auto;
      -webkit-overflow-scrolling: touch;
      padding-bottom: 10px;
    }

    .video-row2 {
      display: flex;
      margin-top: 50px;
      gap: 20px;
      overflow-x: auto;
      -webkit-overflow-scrolling: touch;
      padding-bottom: 10px;
      justify-content: center; /* 居中排列视频 */
    }

    .video-row-nohigh {
      display: flex;
      margin-top: 50px;
      gap: 20px;
      overflow-x: auto;
      -webkit-overflow-scrolling: touch;
      padding-bottom: 10px;
    }

    .video-card {
      flex: 0 0 450px;     /* 固定每个卡片宽度，足够容纳标题 */
      display: flex;
      flex-direction: column;
      align-items: center;
    }

    .video-card video {
      width: 500px;
      height: 300px;       /* 正方形 */
      object-fit: contain; /* 保持比例，缩放，不裁剪 */
      border-radius: 8px;
      background: #f8f7f2;
    }

    .video-card2 {
      flex: 0 0 auto;     /* 固定每个卡片宽度，足够容纳标题 */
      display: flex;
      flex-direction: column;
      align-items: center;
    }

    .original-video-shirt {
      display: block;
      height: 350px;   /* 固定高度 */
      width: auto;     /* 宽度按比例自动缩放 */
      object-fit: contain; /* 保持比例，防止拉伸 */
    }

    .original-video-pen {
      display: block;
      height: 200px;   /* 固定高度 */
      width: auto;     /* 宽度按比例自动缩放 */
      object-fit: contain; /* 保持比例，防止拉伸 */
    }

    .original-video-pen-nohigh {
      display: block;
      height: 500px;   /* 固定高度 */
      width: auto;     /* 宽度按比例自动缩放 */
      object-fit: contain; /* 保持比例，防止拉伸 */
    }

    .video-caption {
      font-size: 20px;
      color: #444;
      margin-top: 8px;
      text-align: center;
      white-space: normal;   /* 允许换行 */
      word-wrap: break-word; /* 长单词也能断开 */
      line-height: 1.4;
      max-width: 350px;      /* 限制在卡片宽度内，不会超出去 */
    }
    .section-title {
      font-size: 1.6em; /* 段落标题更大的字体 */
      font-weight: bold;
      line-height: 1.2;
      margin-bottom: 0.3em;
      display: block;
    }
  </style>
</head>
<body>
    <div class="container">
        <h1>Do You Need Proprioceptive States<br>in Visuomotor Policies?</h1>

        <!-- 作者信息 -->
        <div class="authors">
        <p>
            Juntu Zhao<sup>1,2*</sup>, Wenbo Lu<sup>2,4*</sup>, Di Zhang<sup>2,5</sup>, 
            Yufeng Liu<sup>1,2</sup>, Yushen Liang<sup>4</sup>, Tianluo Zhang<sup>4</sup>, 
            Yifeng Cao<sup>2</sup>, <br>Junyuan Xie<sup>2</sup>, Yingdong Hu<sup>2,3</sup>, 
            Shengjie Wang<sup>4</sup>, Junliang Guo<sup>2‡</sup>, 
            Dequan Wang<sup>1†</sup> and Yang Gao<sup>2,3†</sup>
        </p>

        <p class="notes">
            * Equal Contribution<br>
            * This work was done during the internship at <a href="https://spirit-ai.com" target="_blank">Spirit AI</a><br>
            † Corresponding authors<br>
            ‡ Project leader
        </p>

        <p class="affiliations">
            <sup>1</sup> Shanghai Jiao Tong University,
            <sup>2</sup> Spirit AI,
            <sup>3</sup> Tsinghua University,  
            <sup>4</sup> New York University Shanghai,  
            <sup>5</sup> Tongji University.
        </p>
        </div>

        <div class="meta">
        <div><strong>Published</strong> &nbsp; September 24, 2025</div>
        <div><strong>Email</strong> &nbsp; <a href="https://juntuzhao.run" target="_blank">Juntu Zhao</a> (zhaojuntu@spirit-ai.com)</div>
        </div>

        <div>
        <a href="https://arxiv.org/abs/2509.18644" class="button">
            <img src="imgs/arxiv.png" alt="arXiv logo"> Paper
        </a>
        </div>

        <div style="margin-top: 30px; text-align: center;">
          <video src="mov/teaser_small.mp4" autoplay loop muted style="width: 100%; height: auto; border-radius: 8px;"></video>
        </div>

        <div class="abstract">
        <strong>Abstract -</strong>
        Imitation-learning–based visuomotor policies have been widely used in robot manipulation, where both visual observations and proprioceptive states are typically adopted together for precise control. However, in this study, we find this common practice makes the policy overly reliant on the proprioceptive state input, which causes overfitting to the training trajectories and results in poor spatial generalization. On the contrary, we propose the State-free Policy, removing the proprioceptive state and predicting actions only conditioned on visual observations. The State-free Policy is built in the relative end-effector action space, and should ensure the full task-relevant visual observations, here provided by dual wide-angle wrist cameras. Empirical results demonstrate that the State-free policy achieves significantly stronger spatial generalization than the state-based policy: in real-world tasks such as pick-and-place, challenging shirt-folding, and complex whole-body manipulation, spanning multiple robot embodi- ments, the average success rate improves from 0% to 85% in height generalization and from 6% to 64% in horizontal generalization. Furthermore, they also show advantages in data efficiency and cross-embodiment adaptation, enhancing their practicality for real-world deployment.
        </div>

        <div class="section">
        Proprioceptive states provide direct and accurate robot configuration, but may act as shortcuts, where the policy directly associates absolute states with expert trajectories. Consequently, the policy tends to overfit to the training trajectories and fails to adapt to spatial layout changes. In this study, we propose the <strong>"State-free Policy"</strong>, removing the state input from the visuomotor policiy, based on the relative EEF action space and full task observation. This improves the <strong>spatial generalization</strong> without requiring additional architectural changes or costly diverse data collection. At the same time, we further demonstrate that the State-free Policy also exhibit higher <strong>data efficiency</strong> and better <strong>cross-embodiment adaptation</strong>. Interestingly, we also find that removing the overhead camera can further enhance the policy's spatial generalization performance.
        </div>

        <div class="section">
        <span class="section-title">1. Pick and Place Tasks</span>
        We present that the State-free Policy achieves significantly stronger spatial generalization (both height and horizontal generalization) than the state-based policy across 3 real-world "Pick & Place" tasks:
        <div class="figure" style="margin-top: 20px; text-align: center;">
            <img src="imgs/exp_pick_place.svg" alt="Pick and Place Generalization" style="max-width: 100%; height: auto;">
        </div>
        <div class="video-row" id="videoRow">
          <div class="video-card2">
            <video class="original-video-pen" src="mov/bottle_72_small.mp4" controls muted></video>
            <div class="video-caption">State-based policy vs State-free policy<br>table height = 72 cm (out-of-domain)</div>
          </div>
          <div class="video-card2">
            <video class="original-video-pen" src="mov/bottle_90_small.mp4" controls muted></video>
            <div class="video-caption">State-based policy vs State-free policy<br>table height = 90 cm (out-of-domain)</div>
          </div>
          <div class="video-card2">
            <video class="original-video-pen" src="mov/lid_72_small.mp4" controls muted></video>
            <div class="video-caption">State-based policy vs State-free policy<br>table height = 72 cm (out-of-domain)</div>
          </div>
          <div class="video-card2">
            <video class="original-video-pen" src="mov/lid_90_small.mp4" controls muted></video>
            <div class="video-caption">State-based policy vs State-free policy<br>table height = 90 cm (out-of-domain)</div>
          </div>
        </div>
        </div>

        <div class="section">
            <span class="section-title">2. More Challenging Tasks</span>
            We also evaluate the State-free Policy in horizontal generalization on more challenging tasks: "Fold Shirt" and "Fetch Bottle (whole-body)". The State-free Policy still shows significantly improved performance compared to the state-based policy.
          
            <!-- 三线表 -->
            <table style="width: 100%; border-collapse: collapse; margin: 20px 0; text-align: center;">
              <thead>
                <tr>
                  <th style="border-top: 2px solid #000; border-bottom: 2px solid #000; text-align: left; padding: 8px; font-weight: normal;">Task name</th>
                  <th style="border-top: 2px solid #000; border-bottom: 2px solid #000; padding: 8px; font-weight: normal;"><em>Fold Shirt</em></th>
                  <th style="border-top: 2px solid #000; border-bottom: 2px solid #000; padding: 8px; font-weight: normal;"><em>Fetch Bottle</em></th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td style="padding: 8px; text-align: left;">w/ state (normal wrist-camera)</td>
                  <td style="padding: 8px;">0.183</td>
                  <td style="padding: 8px;">0.117</td>
                </tr>
                <tr>
                  <td style="padding: 8px; text-align: left;">w/o state (normal wrist-camera)</td>
                  <td style="padding: 8px;">0.834</td>
                  <td style="padding: 8px;">0.784</td>
                </tr>
              </tbody>
              <tfoot>
                <tr>
                  <td colspan="3" style="border-top: 2px solid #000;"></td>
                </tr>
              </tfoot>
            </table>
              
            <div class="video-row2" id="videoRow">
              <div class="video-card2">
                <video class="original-video-shirt" src="mov/shirt_small.mp4" controls muted></video>
                <div class="video-caption">State-based policy vs State-free policy<br>moving both two arms 15 cm</div>
              </div>
              <div class="video-card2">
                <video class="original-video-shirt" src="mov/whole_body_small.mp4" controls muted></video>
                <div class="video-caption">State-based policy vs State-free policy<br>moving the fridge 10 cm</div>
              </div>
            </div>
          </div>
        

          <!--
          <div class="section" style="display: flex; align-items: center; gap: 20px; margin-top: 50px;">

            <div style="flex: 0 0 45%;">
              <img src="imgs/data_scale.svg" alt="Data Efficiency" style="width: 100%; height: auto;">
              <div style="margin-top: 10px; text-align: justify; text-justify: inter-word; font-style: italic; margin-bottom: 10px; color: #555;">
                <strong>Figure 5.</strong> Evaluation success rates (in-domain) on the “Pick Pen” task with varying amounts of fine-tuning data.
              </div>
            </div>
          
            <div style="flex: 1; text-align: justify; text-justify: inter-word;">
              <span class="section-title">Data Efficiency</span>
              Even in in-domain settings, state-based policies require diverse demonstrations to avoid overfitting to specific trajectories, which greatly increases data collection costs. 
              In contrast, State-free Policies are less prone to memorizing specific trajectories and can achieve comparable performance with fewer fine-tuning data, thereby enhancing data efficiency and practicality for real-world deployment. 
              We validate this on the in-domain "Pick Pen" task using dual wide-angle wrist-cameras, varying the fine-tuning data to 300, 200, 100, and 50 episodes, and measuring performance after 2 and 4 fine-tuning epochs. 
              The evaluation results show that reducing data causes state-based policies to overfit and lose success, while State-free Policies maintain much higher performance.
            </div>
        
          </div>
          -->






          <div class="section" style="margin-top: 50px; text-align: justify; text-justify: inter-word;">

          

            <div style="float: left; width: 700px; margin-right: 20px; margin-bottom: 10px; text-align: justify;">
              <img src="imgs/data_scale.svg" alt="Data Efficienc" style="width: 100%; height: auto;">
            </div>
          
            <span class="section-title">3. Data Efficiency</span>
              The state-based policy require diverse demonstrations to avoid overfitting to specific trajectories, greatly increasing the data collection cost. 
              But the State-free Policy is less prone to memorizing specific trajectories and can achieve comparable performance with fewer fine-tuning data.
              We validate this on the in-domain "Pick Pen" task using dual wide-angle wrist-cameras, varying the fine-tuning data to 300, 200, 100, and 50 episodes, and measuring performance after 2 and 4 fine-tuning epochs. 
              The evaluation results show that reducing data causes the state-based policy to overfit and lose success, while the State-free Policy maintain much higher performance.
          

            <div style="clear: both;"></div>
          
        </div>
          
          



          <div class="section">
            <span class="section-title">4. Cross-Embodiment Fine-Tuning</span>
            The State-free Policy also benefit cross-embodiment fine-tuning, as it avoids the issue of aligning with a new state space. We validate this on the in-domain "Fold Shirt" task using the human-like robot. Policies are first trained on dual-arm Arx5 and then adapted to a human-like dual-arm robot. The evaluation results show that the State-free Policy adapt much faster across embodiments, achieving substantially higher success rates than the state-based policy under the same fine-tuning epochs. 
            This indicates that the State-free Policy have better cross-embodiment ability than the state-based policy.
          
            <!-- 三线表直接放在标题下面 -->
            <table style="width: 100%; border-collapse: collapse; margin: 10px 0 20px 0; text-align: center;">
              <thead>
                <tr>
                  <th style="border-top: 2px solid #000; border-bottom: 2px solid #000; text-align: left; padding: 8px; font-weight: normal;">State input</th>
                  <th style="border-top: 2px solid #000; border-bottom: 2px solid #000; padding: 8px; font-weight: normal;">Fine-tune 5k steps</th>
                  <th style="border-top: 2px solid #000; border-bottom: 2px solid #000; padding: 8px; font-weight: normal;">Fine-tune 10k steps</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td style="padding: 8px; text-align: left;">w/ state</td>
                  <td style="padding: 8px;">0.333</td>
                  <td style="padding: 8px;">0.767</td>
                </tr>
                <tr>
                  <td style="padding: 8px; text-align: left;">w/o state</td>
                  <td style="padding: 8px;">0.700</td>
                  <td style="padding: 8px;">0.967</td>
                </tr>
              </tbody>
              <tfoot>
                <tr>
                  <td colspan="3" style="border-top: 2px solid #000; text-align: left; padding: 8px;"></td>
                </tr>
              </tfoot>
            </table>
          </div>










          <div class="section">
            <span class="section-title">5. Rethinking the Sensor Design</span>
            We find that removing the overhead camera can further enhance the policy's spatial generalization performance. We evaluate this through experiments on the "Pick Pen" task under 3 more challenging scenarios:
          
            <!-- 表格直接放在标题下面 -->
            <table style="width: 100%; border-collapse: collapse; margin: 10px 0 20px 0; text-align: center;">
              <thead>
                <tr>
                  <th style="border-top: 2px solid #000; border-bottom: 2px solid #000; text-align: left; padding: 8px; font-weight: normal;">Overhead camera input</th>
                  <th style="border-top: 2px solid #000; border-bottom: 2px solid #000; padding: 8px; font-weight: normal;">Table height 100 cm</th>
                  <th style="border-top: 2px solid #000; border-bottom: 2px solid #000; padding: 8px; font-weight: normal;">Raising pen holder height</th>
                  <th style="border-top: 2px solid #000; border-bottom: 2px solid #000; padding: 8px; font-weight: normal;">Moving pen holder 20 cm</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td style="padding: 8px; text-align: left;">w/ overhead cam</td>
                  <td style="padding: 8px;">0</td>
                  <td style="padding: 8px;">0.467</td>
                  <td style="padding: 8px;">0</td>
                </tr>
                <tr>
                  <td style="padding: 8px; text-align: left;">w/o overhead cam</td>
                  <td style="padding: 8px;">1.0</td>
                  <td style="padding: 8px;">0.867</td>
                  <td style="padding: 8px;">0.800</td>
                </tr>
              </tbody>
              <tfoot>
                <tr>
                  <td colspan="4" style="border-top: 2px solid #000; text-align: left; padding: 8px;"></td>
                </tr>
              </tfoot>
            </table>

            <div class="video-row-nohigh">
              <div class="video-card2">
                <video class="original-video-pen-nohigh" src="mov/nohigh_100_small.mp4" controls muted></video>
                <div class="video-caption">Without the overhead camera, table height = 100 cm</div>
              </div>
              <div class="video-card2">
                <video class="original-video-pen-nohigh" src="mov/nohigh_double_small.mp4" controls muted></video>
                <div class="video-caption">Without the overhead camera, double the pen holder height</div>
              </div>
              <div class="video-card2">
                <video class="original-video-pen-nohigh" src="mov/nohigh_position_small.mp4" controls muted></video>
                <div class="video-caption">Without the overhead camera, moving the pen holder for 20 cm</div>
              </div>
            </div>
          
              Results show that without the overhead camera, the policy achieve significantly higher success rates than that with the overhead camera.
              This finding motivates us to rethink sensor design, perhaps removing the overhead camera, for future visuomotor policies.
          </div>


          <div class="section">
            <span class="section-title">6. Implementation Example</span>
            The State-free Policy can be easily integrated into existing visuomotor policies, requiring only the simple removal of proprioceptive state inputs from the model. For example, in the Lerobot platform's <span style="font-style: italic;"></span>π<sub>0</sub></span> policy:
            
            <div style="
                background-color: #dcdad6;
                color: #111111;
                padding: 20px;
                border-radius: 12px;
                font-family: monospace;
                font-size: 0.8em;
                white-space: pre-wrap;
                word-wrap: break-word;
                text-align: left;
                margin: 20px 0;
            ">
class PI0FlowMatching(nn.Module):
    <span style="color: #228b22;"># ... other class functions ...</span>
    def embed_suffix(self, state, noisy_actions, timestep):
        <span style="color: #228b22;"># ... other processing ...</span>    
        if self.use_state:
          state_emb = self.state_proj(state)
          embs.append(state_emb)
          state_mask = torch.ones(bsize, nstates, dtype=torch.bool, device=device)
          pad_masks.append(state_mask)
          att_masks += [1]
        <span style="color: #228b22;"># ... other processing ...</span>
          </div>
        </div>


          <div class="section">
            <span class="section-title">Conclusion</span>
            In this study, we propose State-free Policies, under two conditions: the relative end-effector (EEF) action space and full task observation through sufficiently comprehensive visual information. 
            Without state input, these policies maintain perfect in-domain performance while achieving significant improvements in spatial generalization. 
            State-free Policies also reduce the costly real-world data need, enable more efficient cross-embodiment adaptation, and inspire new directions in future sensor design. 
            Our findings shed new light on how State-free Policies can serve as a foundation for building more generalizable robotic learning systems.
          </div>




          <div class="section" style="margin-top: 50px;">
            <span class="section-title">BibTeX</span>
          
            <div style="
                background-color: #dcdad6;
                color: #111111;
                padding: 20px;
                border-radius: 12px;
                font-family: monospace;
                font-size: 0.7em;
                white-space: pre-wrap;
                word-wrap: break-word;
                text-align: left;
                margin: 0;
            ">
@article{zhao2025nostate,
  title={Do You Need Proprioceptive States in Visuomotor Policies?},
  author={Juntu Zhao and Wenbo Lu and Di Zhang and Yufeng Liu and Yushen Liang and Tianluo Zhang and Yifeng Cao and Junyuan Xie and Yingdong Hu and Shengjie Wang and Junliang Guo and Dequan Wang and Yang Gao},
  year={2025},
  eprint={2509.18644},
  archivePrefix={arXiv},
  primaryClass={cs.RO},
  url={https://arxiv.org/abs/2509.18644}
}
            </div>
          </div>

          
    </div>
</body>
</html>
